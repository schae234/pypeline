#!/usr/bin/python2

from __future__ import print_function
import os
import sys
import numpy
import re
import bisect
import time
from optparse import OptionParser
from collections import defaultdict


class VCFFilter(object):
    def __init__(self):
        self.percentile = None
        self.field = None
        self.qual = None
        self.thresh = None
        self.union_positions = None
        self.map_positions = None
        self.out = sys.stdout
        self.log_file = sys.stderr
        self.skip_chroms = None
        self.keep_chroms = None
        self.num_call_sets = None
        self.repeats = None
        self.within = None
        self.allelic = None
        self.emit_type = "all"
        # Set counters
        self.num_within = 0
        self.num_allelic = 0
        self.num_repeat = 0
        self.num_field = 0


    def get_percentile_cutoff(self,vcf_file,perc):
        ''' Return the field cutoff for a specific field cutoff ''' 
        with open(vcf_file,'r') as file:
            quals = numpy.array(
                [float(line.split()[5]) for line in file if not line.startswith("#") ]
            )
        qual_cutoff = numpy.percentile(quals,perc)
        return qual_cutoff 

    def process(self,vcf_file):
        ''' This method performs the filtering. It assumes you set up the filters ahead of time '''
        # Filter the vcf file
        with open(vcf_file,'r') as invcf:
            line_num = 0
            for line in invcf:
                if line.startswith('#'):
                    fields = line.split()
                    self.indivs = fields[9:]
                    # headers always get printed
                    print(line,file=self.out,end="")
                else:
                    fields = line.split()

                    if self.allelic and len(fields[4].split(',')) >= self.allelic:
                        continue
                        fields[6] += ";ALLELIC"
                        self.num_allelic += 1
                    if self.within and self.within[line_num]['skip']:
                        fields[6] += ";WITHIN"
                        self.num_within += 1
                    if self.skip_chroms and fields[0] in self.skip_chroms:
                        fields[6] += ";SKIP_CHROM"
                    if self.keep_chroms and fields[0] not in self.keep_chroms:
                        fields[6] += ";NOT_KEEP_CHROM"
                    if self.qual and float(fields[5]) < self.thresh:
                        fields[6] += ";LOW_QUAL_THRESH"
                    if self.field and self.thresh:
                        field = re.search(str(';?'+self.field+'=([^;]*)(;?)'),fields[7])
                        if field == None:
                            fields[6] += ";NO_FIELD"
                            self.log("No {} field for variant {} {}".format(self.field,fields[0],fields[1]))
                        else:
                            if float(field.group(1)) < self.thresh:
                                fields[6] += ";LOW_"+self.field.upper()
                                self.num_field += 1
                    if self.repeats and self.in_repeat_region(fields[0],int(fields[1])):
                        fields[6] += ";REPEAT"
                        self.num_repeat += 1
                    if self.union_positions and int(fields[1]) not in self.union_positions[fields[0]]:
                        fields[6] += ";UNION"
                    if self.map_positions and int(fields[1]) not in self.map_positions[fields[0]]:
                        fields[6] += ";MAP"
                    if self.num_call_sets:
                        sets = re.search(';?set=([^;]*)(;?)',fields[7])
                        if sets == None:
                            self.log("No set found for {} {}".format(fields[0],fields[1]))
                        else:
                            if len(sets.group(1).split('-')) < self.num_call_sets or sets.group(1) == 'FilteredInAll':
                                fields[6] += ";LOW_CALL_SET"
                    # Emit the processed variant to the output file
                    self.emit(fields)
                    line_num += 1

    def populate_intersect(self,vcf_file):
        self.log("Reading in union file: {}".format(vcf_file))
        positions = defaultdict(list)
        with open(vcf_file,'r') as file:
            for line in file:
                if line.startswith('#'):
                    continue
                line = line.rstrip()
                line = line.split()
                positions[line[0]].append(int(line[1]))
        num_vars_seen = 0
        for chr in positions.keys():
            # covert to set for fast intersection checks
            positions[chr] = set(positions[chr])
            num_vars_seen += len(positions[chr])
        self.log("Found {} variants in union file".format(num_vars_seen))
        self.union_positions = positions

    def populate_map(self,map_file):
        positions = defaultdict(list)
        with open(map_file,'r') as file:
            for line in file:
                line=line.strip()
                chr,id,cm,pos = line.split()
                positions['chr'+chr].append(int(pos))
        for chr in positions.keys():
            # covert to set for fast intersection checks
            positions[chr] = set(positions[chr])
        self.map_positions = positions
    
    def populate_repeat(self,repeat_file):
        ranges = defaultdict(lambda: defaultdict(list))
        with open(repeat_file,'r') as file:
            for line in file:
                chr,start,end = line.strip().split() 
                ranges[chr]['start'].append(int(start))
                ranges[chr]['end'].append(int(end))
        self.repeats = ranges
    
    def in_repeat_region(self,chrom,position):
        index = min(bisect.bisect_left(self.repeats[chrom]['start'],position)-1,0)
        if self.repeats[chrom]['start'][index] < position and self.repeats[chrom]['end'][index] > position:
            return True
        else:
            return False

    def populate_within(self, not_within, vcf_file):
        i = 0
        self.within = []
        with open(vcf_file,'r') as file:
            for line_num,line in enumerate(file):
                if line.startswith('#'):
                    continue
                else:
                    fields = line.strip().split()
                    if self.verbose and line_num % 1000000 == 0:
                        self.log("Populating within line: {}".format(line_num))
                    if i >  2:
                        if abs(self.within[i-2]['pos']-self.within[i-3]['pos']) < not_within:
                            self.within[i-2]['skip'] = True
                            self.within[i-3]['skip'] = True
                        if abs(self.within[i-2]['pos']-self.within[i-1]['pos']) < not_within:
                            self.within[i-2]['skip'] = True
                            self.within[i-1]['skip'] = True
                    self.within.append({
                        'pos'  : int(fields[1]),
                        'skip' : False
                    })
                    i+=1
                    
    def log(self,*args):
        print(time.ctime(),' - ',*args,file=self.log_file)

    def emit(self,fields):
        if self.emit_type == 'pass' and fields[6] != "PASS":
            return None
        if self.emit_type == 'filtered' and fields == 'PASS':
            return None
        print("\t".join(fields),file=self.out)
            
    def filter_totals(self):
        self.log(''' 
            Filter totals:
            within {}
            allelic {}
            repeat {}
            field {}
        '''.format(self.num_within,self.num_allelic,self.num_repeat,self.num_field)) 


def main(argv):
    parser = OptionParser()
    parser.add_option("--filter",default=None, type=str,help="filter out variants that do not match based on FILTER field, e.g. LowQual")
    parser.add_option("--field", default=None, type=str, help="Used with percentile or threshold arguments to filter out based on a FIELD arg")
    parser.add_option("--qual", action="store_true", default=None, help="Used with percentile or threshold arguments to filter out based on a QUAL arg")
    parser.add_option("--thresh", default=None,type=float,help='filter out --field values under this threshold')
    parser.add_option("--percentile", default = None, type = int,help="filter out --field values under this percentile")
    parser.add_option('--skip_chrom',action="append",type=str,help="Skip variants on chroms. Can be specified multiple times")
    parser.add_option('--keep_chrom',action="append",type=str,help="keep variants on chroms. Can be specified multiple times")
    parser.add_option('--num_call_sets',type=float,help="the minimum number of call sets a variant must be called in")
    parser.add_option('--not_within',type=int,default=None,help="the variant is not within X base pairs to another variant, if so, both get filtered")
    parser.add_option('--allelic',type=int,default=None,help="Filter out variants which have more alleles than X")
    # Options that require extraneous files
    parser.add_option('--repetitive',type=str,help="Filters out variants in repetitive regions. Supply a three columned file with chr,start,end regions")
    parser.add_option('--map_file',type=str,default=None,help="Only include snps in Plink map file")
    parser.add_option("--intersect_vcf", default = None, type=str, help="Only match variants within another vcf")
    parser.add_option("--exclude_vcf",default=None, type=str,help="Only match variants not within another vcf")
    # Options related to output and formatting
    parser.add_option("--verbose", default = False, action="store_true",help="how much do you want to know?")
    parser.add_option('--emit',type=str,default="all",help="Controls which variants to print out. One of all, pass, or filtered")
    #parser.add_option('--inline',action="store_true",default=False,help="Modify the VCF inline")
    
    parser.add_option("-o",'--out', default=sys.stdout )
    options, args = parser.parse_args(argv) 

    # Create an empty filter and add based on options
    flt = VCFFilter()
    flt.emit_type = options.emit
    flt.verbose = options.verbose
    # Check to see if we are performing proximity checks
    flt.log("Starting Analysis...")
    # Check to see if we are performing union checks
    if options.intersect_vcf != None:
        flt.populate_intersect(options.intersect_vcf)
    # Check for map based filters
    if options.map_file != None:
        flt.populate_map(options.map_file)
    # Check for chrom based filters
    if options.skip_chrom and options.keep_chrom:
        exit("Cannot specify --keep_chrom AND --skip_chrom")
    if options.skip_chrom:
        flt.skip_chroms = set(options.skip_chrom)
    if options.keep_chrom:
        flt.keep_chroms = set(options.keep_chrom)
    # Check for field based filters, can be either a thresh OR percentile, not both
    if options.field and (options.field or options.percentile):
        flt.field = options.field
        flt.thresh = options.thresh
        flt.percentile = options.percentile
    # Check the threshold based filter
    if options.qual:
        if not options.thresh and not options.percentile:
            exit("--qual requires --thresh or --percentile")
        flt.qual = options.qual
        flt.thresh = options.thresh
    # Check for call set based filters
    if options.num_call_sets:
        flt.num_call_sets = options.num_call_sets
    # Check for percentile based filters
    if options.percentile:
        flt.qual = "QUAL"
        flt.thresh = flt.get_percentile_cutoff(args[0],options.percentile)
        print("QUAL THRESH: {}".format(flt.thresh),file=sys.stderr)
    if options.repetitive:
        flt.populate_repeat(options.repetitive)
    if options.out != sys.stdout:
        flt.out = open(options.out,'w')
    # Check for FILTER based filters
    if options.filter:
        flt.filter = options.filter
    if options.allelic:
        flt.allelic = options.allelic

    # Process input files
    for filename in args:
        # Check if we are filtering proximity:
        if options.not_within:
            flt.populate_within(options.not_within,filename)
        flt.process(filename)
    if flt.verbose:
        flt.filter_totals()
    flt.log("... analysis ended")

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
